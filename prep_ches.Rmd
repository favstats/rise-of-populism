---
title: "My_Template"
output: html_notebook
---

# Load in Packages

```{r}
#install.packages("pacman")
#pacman::p_install_gh("systats/binoculaR")
pacman::p_load(tidyverse, magrittr, haven, ggthemes, sjPlot, sjmisc, sjstats, binoculaR, janitor, here, Amelia, mlbench, psych, ggrepel, cluster, factoextra, rvest)

range01 <- function(x){(x - min(x, na.rm = T)) / (max(x, na.rm = T) - min(x, na.rm = T))}

```


# Load in Data

```{r}
ches <- haven::read_dta(here("data", "1999_2014_CHES.dta"))
```


# Filter Data

```{r}
ches %>% 
  mutate(cntry = to_label(country))

# create a missing map
ches %>% 
  arrange(year, country) %>% 
  missmap(col=c("black", "grey"), legend=FALSE)
```


# Recoding

```{r}
mod1 <- lm(antielite_salience ~ position, data = ches)

 
ches %>% 
  select(antielite_salience, corrupt_salience, position, eu_budgets, eu_cohesion, eu_foreign) %>% 
  na.omit() %>% 
  cor()

ches %>% 
  select(antielite_salience, corrupt_salience, position, eu_budgets, eu_cohesion, eu_foreign) %>% 
  na.omit() %>% 
  fa(2)


plot_model(mod1, show.data = T)


ches %>% 
  select(antielite_salience, position, nationalism) %>% 
  na.omit() %>% 
  cor()

```


# Analysis

```{r}
ches %>% 
  select(sociallifestyle, civlib_laworder, galtan) %>% 
  na.omit() %>% 
  cor()

ches %>% 
  select(sociallifestyle, civlib_laworder, galtan) %>% 
  pca()
```


```{r}
ches %<>% 
  mutate(populism = antielite_salience + corrupt_salience) %>% 
  mutate(populism2 = range01(range01(antielite_salience) + 
                               (1 - range01(position)))*100) %>% #+ 
                           #    (1 - range01(eu_budgets)))*100) %>% 
  mutate(liberalism = sociallifestyle + civlib_laworder + galtan) %>% 
  mutate(populism = range01(populism)*100) %>% 
  mutate(liberalism = range01(liberalism)*100) %>% 
  mutate(party_cntry = paste0(to_label(country), "_", party)) %>% 
  mutate(family = to_label(family)) %>%
  filter(year > 2009)

ches %>% 
  ggplot(aes(liberalism, populism, color = family)) + 
  geom_point() +
  geom_text_repel(aes(liberalism, populism, label = party_cntry)) +
  guides(text = F) +
  ggthemes::theme_hc() +
  ggthemes::scale_color_hc()

ggsave(file = here("images", "party_alignment.png"), height = 10, width = 10)


ches_pop <- ches %>% 
  filter(populism >= 60)

length(unique(ches_pop$country))
length(unique(ches$country))

table(1-range01(ches$position))
```
```{r}
ches %>% 
  ggplot(aes(liberalism, antielite_salience, color = family)) + 
  geom_point() +
  geom_text_repel(aes(liberalism, antielite_salience, label = party_cntry)) +
  guides(text = F) +
  ggthemes::theme_hc() #+
#  ggthemes::scale_color_hc() 

ggsave(file = here("images", "party_alignment2.png"), height = 10, width = 10)


ches_elite <- ches %>% 
  filter(antielite_salience >= 7.5)

length(unique(ches_elite$country))
length(unique(ches$country))

#table(to_label(ches_elite$country))
```

# extracting party and country names 

```{r}
#devtools::install_github("expersso/pdftables")

# pdftable_api <- "opj9i5owyg40"
# 
# pdftables::convert_pdf("codebooks/party_tables2.pdf",
#                        "codebooks/party_tables.csv",
#                        api_key = pdftable_api)

# pdftables::convert_pdf("codebooks/country_names.pdf",
#                        "codebooks/country_names.csv",
#                        api_key = pdftable_api)

party_tables <- read_csv("codebooks/party_tables.csv")


colnames(party_tables) <- party_tables[1,]

party_tables %<>% 
  janitor::clean_names() %>% 
  select(party_id, party_name, party_name_english) %>% 
  filter(party_name != "Party Name") %>% 
  filter(party_name_english != "Party Name (English)") %>% 
  na.omit()

ches <- party_tables %>% 
  mutate(party_id = as.numeric(party_id)) %>% 
  left_join(ches, by = "party_id")

country_names <- read_csv("codebooks/country_names.csv") %>% janitor::clean_names()

colnames(country_names) <- country_names[1,]

country_names <- rbind(country_names[,1:3], 
                       country_names[,4:6]) 

colnames(country_names) <- c("id", "cntry_short", "cntry")

country_names %<>% 
  na.omit() %>% 
  select(cntry_short, cntry)

ches %<>% 
  mutate(cntry_short = str_to_upper(to_label(country))) %>% 
  left_join(country_names, by = "cntry_short")
```

```{r}
ches %>% 
  ggplot(aes(liberalism, populism2, color = family)) + 
  geom_point() + 
  geom_hline(yintercept = 55, linetype = 4) +
  geom_text_repel(aes(liberalism, populism2, label = party_cntry)) +
  guides(text = F) +
  ggthemes::theme_hc() +
  ggthemes::scale_color_hc()

ggsave(file = here("images", "party_alignment3.png"), height = 10, width = 10)
```

# Function for getting website.
```{r}
getWebsite <- function(name)
{
    url = URLencode(paste0("https://www.google.com/search?q=",name))

    page <- read_html(url)

    results <- page %>%
      html_nodes("cite") %>% # Get all notes of type cite. You can change this to grab other node types.
      html_text()

    result <- results[1]

    return(as.character(result)) # Return results if you want to see them all.
}

fix_the_string <- function(string) {
  string %<>%
#  unique() %>%
  iconv(from = "Windows-1252", to = "UTF-8") %>% 
  stringi::stri_replace_all_regex("<U\\+([[:alnum:]]{4})>", "\\\\u$1") %>% 
  stringi::stri_replace_all_regex("<U\\+([[:alnum:]]{5})>", "\\\\U000$1") %>% 
  stringi::stri_replace_all_regex("<U\\+([[:alnum:]]{6})>", "\\\\U00$1") %>% 
  stringi::stri_replace_all_regex("<U\\+([[:alnum:]]{7})>", "\\\\U0$1") %>% 
  stringi::stri_replace_all_regex("<U\\+([[:alnum:]]{8})>", "\\\\U$1") %>% 
  stringi::stri_replace_all_regex("<U\\+([[:alnum:]]{1})>", "\\\\u000$1") %>% 
  stringi::stri_replace_all_regex("<U\\+([[:alnum:]]{2})>", "\\\\u00$1") %>% 
  stringi::stri_replace_all_regex("<U\\+([[:alnum:]]{3})>", "\\\\u0$1") %>% 
  stringi::stri_unescape_unicode() %>% 
  stringi::stri_enc_toutf8()
}

ches %<>%
  mutate(party_name = fix_the_string(party_name)) %>%
  mutate(party_name_english = fix_the_string(party_name_english)) 

# links <- ches$party_name %<>%
#   unique() %>%
#   paste(unique(ches$cntry), "english wikipedia") %>%
#   map_chr(getWebsite)
# 
# save(links, file = "data/party_links.Rdata")

load("data/party_links.Rdata")

merger <- ches$party_name %>%
  unique() %>%
  cbind(links) %>%
  data.frame()

colnames(merger) <- c("party_name", "links")

ches %<>%
  left_join(merger, by = "party_name")


table(ches$party_name)

# ches_pop2 <- ches %>% 
#   filter(populism2 >= 55) %>% 
#   mutate(lr_popul = ifelse(liberalism >= 50, 
#                            "Right-Wing Populism", 
#                            "Left-Wing Populism")) %>% 
#   mutate(links = links)
# 

#length(unique(ches_pop2$country))
length(unique(ches$country))

#dput(ches_pop2$party_cntry)

# ches_pop2 %<>% 
#   select(party_cntry, party_name, party_name_english, populism2, liberalism, 
#        electionyear, vote, seat, epvote, family, lr_popul, links)

# save(ches_pop2, file = "data/party_data.Rdata")

# 
# library(xml2) 
# library(httr) 
# library(rvest) 
# library(purrr) 
# library(dplyr)  
# 
# to_get <- seq(0, 150, 10) 
# pb <- progress_estimated(length(to_get))  
# 
# map_chr(to_get, function(i) {   
#   pb$tick()$print()   searchurl <- paste("http://pqasb.pqarchiver.com/djreprints/results.html?st=advanced&qrytxt=bankruptcy&sortby=chron&datetype=6&frommonth=01&fromday=01&fromyear=1908&tomonth=12&today=31&toyear=1908&by=&title=&at_hist=article&at_hist=editorial_article&at_hist=front_page&type=historic&start=", i, sep="")   htmlweb <- read_html(searchurl)   nodeweb <- html_node(htmlweb, "td > font.result_title > a")   
#   
# textweb <- html_text(nodeweb)   
# sys.sleep(sample(10, 1) * 0.1)   textweb }) -> titles 
# 
# print(trimws(titles))

table(ches$year)

```


# Clustering

```{r}
set.seed(2018)
ches_cluster <- ches %>% 
  select(party_cntry, liberalism, populism2) %>% 
  na.omit() %>% 
  as.data.frame()

row_names <- ches_cluster$party_cntry

ches_cluster %<>% 
  select(-party_cntry) %>% 
  mutate_all(scale) 

rownames(ches_cluster) <- row_names

distance <- get_dist(ches_cluster)
png("images/distance_matrix.png", width = 1800, height = 1600)
fviz_dist(distance, 
                             gradient = list(low = "#00AFBB", 
                                             mid = "white",
                                             high = "#FC4E07"))
dev.off()

k3 <- kmeans(ches_cluster, centers = 4, nstart = 25)

fviz_cluster(k3, data = ches_cluster)


ches %>%
  select(party_cntry, liberalism, populism2) %>% 
  na.omit() %>% 
  mutate(cluster = k3$cluster,
         state = row.names(ches_cluster)) %>%
  ggplot(aes(liberalism, populism2, color = factor(cluster))) + 
  geom_point() +
  geom_text_repel(aes(liberalism, populism2, label = party_cntry)) +
  guides(text = F) +
  ggthemes::theme_hc() +
  ggthemes::scale_color_gdocs()

ggsave(file = here("images", "party_alignment5.png"), height = 10, width = 10)


```

# Save Cluster Data

```{r}
ches_pop3 <- ches %>%
  select(party_cntry, party_name, party_name_english, populism2, liberalism, family, links) %>%
  na.omit() %>%
  mutate(cluster = k3$cluster) %>%
  mutate(cluster = case_when(
    cluster == 1 ~ "Illiberal Populism",
    cluster == 2 ~ "Liberal Populism",
    TRUE ~ "Establishment"
  ))

#load("data/ches_pop3.Rdata")


table(ches_pop3$cluster)

populist_parties <- ches_pop3 %>%
  filter(cluster != "Establishment")

save(populist_parties, file = "data/populist_parties.Rdata")
```


```{r}
set.seed(123)
fviz_nbclust(ches_cluster, kmeans, method = "wss")
fviz_nbclust(ches_cluster, kmeans, method = "silhouette")


gap_stat <- clusGap(ches_cluster, FUN = kmeans, nstart = 25,
                    K.max = 10, B = 50)

fviz_gap_stat(gap_stat)
```

```{r}
ches_cluster <- ches %>% 
  select(party_cntry, antielite_salience, position, sociallifestyle, galtan, civlib_laworder) %>% 
  na.omit() %>% 
  as.data.frame()

row_names <- ches_cluster$party_cntry

ches_cluster %<>% 
  select(-party_cntry) %>% 
  mutate_all(scale) 

rownames(ches_cluster) <- row_names

distance <- get_dist(ches_cluster)
png("images/distance_matrix.png", width = 1800, height = 1600)
fviz_dist(distance, 
                             gradient = list(low = "#00AFBB", 
                                             mid = "white",
                                             high = "#FC4E07"))
dev.off()

k3 <- kmeans(ches_cluster, centers = 4, nstart = 25)

fviz_cluster(k3, data = ches_cluster)

ches %>%
  select(party_cntry, liberalism, populism2) %>% 
  na.omit() %>% 
  mutate(cluster = k3$cluster,
         state = row.names(ches_cluster)) %>%
  ggplot(aes(liberalism, populism2, color = factor(cluster))) + 
  geom_point() +
  geom_text_repel(aes(liberalism, populism2, label = party_cntry)) +
  guides(text = F) +
  ggthemes::theme_hc() +
  ggthemes::scale_color_gdocs()

ggsave(file = here("images", "party_alignment6.png"), height = 10, width = 10)


```


```{r}
set.seed(123)
fviz_nbclust(ches_cluster, kmeans, method = "wss")
fviz_nbclust(ches_cluster, kmeans, method = "silhouette")


gap_stat <- clusGap(ches_cluster, FUN = kmeans, nstart = 25,
                    K.max = 10, B = 50)

fviz_gap_stat(gap_stat)
```




```{r}
ess <- read_spss("data/ess_round8.sav")


```

